# Day 5: Python Functions and AWS Project Planning
**Date:** October 17, 2025 (Friday)
**Time:** 90 minutes (late evening session)
**Focus:** Introduction to Python functions, AWS architecture overview, weekend project preparation

## Overview

Tonight was bridge night between Week 1 fundamentals and tomorrow's first hands-on AWS project. I learned the final Python concept I needed before starting AWS work - functions - and spent focused time understanding the S3 and CloudFront architecture I'll be building tomorrow. By the end of tonight's session, I have a clear execution plan for creating my first production-grade cloud infrastructure.

## Python Functions: Making Code Reusable

Functions are named blocks of code that you can call multiple times without rewriting them. Instead of copying and pasting the same calculation or logic throughout a program, you write it once inside a function definition and then invoke that function whenever you need it. This makes code more maintainable, more readable, and less error-prone.

I started with a single-parameter function that calculates monthly EC2 costs from hourly rates. The function takes one input, performs a calculation using that input, and returns the result. This pattern of input, processing, and output is fundamental to all function design.
```python
def calculate_monthly_cost(hourly_rate):
    hours_per_month = 730
    monthly_cost = hourly_rate * hours_per_month
    return monthly_cost

t2_micro_cost = calculate_monthly_cost(0.0116)
print(f"t2.micro monthly cost: ${t2_micro_cost}")
```

The beauty of this approach became clear when I called the function multiple times with different instance types. I calculated costs for t2.micro, t2.small, t2.medium, and even tested a t3.trainium instance which came out to over three hundred thousand dollars per month. Each call used the same calculation logic but produced different results based on the input I provided. Writing the calculation once and reusing it multiple times is far more efficient than copying those three lines of code for every instance type I want to check.

I then moved to a multi-parameter function that calculates total infrastructure costs across multiple instances and time periods. This function accepts three separate parameters - hourly rate, number of instances, and hours of operation - and uses all three in its calculation.
```python
def calculate_total_cost(hourly_rate, num_instances, hours):
    cost_per_instance = hourly_rate * hours
    total_cost = cost_per_instance * num_instances
    return total_cost

result = calculate_total_cost(0.0116, 5, 720)
print(f"Running 5 t2.micro instances for 30 days: ${result}")
```

This exercise taught me how parameters map to arguments when calling functions. The first value I pass becomes hourly_rate, the second becomes num_instances, and the third becomes hours. The order matters because Python assigns arguments to parameters positionally from left to right. Understanding this mapping is crucial for reading function documentation and knowing what values to pass when calling functions I didn't write myself.

An important question came up during this exercise about the difference between passing multiple separate values in parentheses versus passing a list in square brackets. When you call a function with comma-separated values inside parentheses, you're passing multiple individual arguments that each map to their own parameter. When you create a list with square brackets, you're creating a single data structure that contains multiple items. Functions are typically designed to accept individual parameters rather than lists because it makes the code more explicit and readable. You can tell at a glance what each value represents rather than having to remember arbitrary list positions.

## AWS Architecture Understanding: S3 and CloudFront

The second half of tonight's session focused on understanding the architecture I'll build tomorrow. This isn't just a tutorial exercise - it's a production-grade pattern used by major companies to serve static content globally with high performance and reliability.

S3, which stands for Simple Storage Service, is AWS's object storage platform. Unlike traditional file systems with hierarchical directories, S3 uses a flat structure of buckets and objects. A bucket is a top-level container with a globally unique name, and objects are the files you store inside that bucket. What makes S3 useful for hosting websites is its static website hosting feature, which allows S3 to serve files directly to web browsers just like a traditional web server would. You upload your HTML, CSS, JavaScript, and images to a bucket, enable static website hosting, configure the right permissions to make the content publicly accessible, and S3 handles serving those files to anyone who requests them.

CloudFront is AWS's content delivery network. It takes your content from S3 and distributes it to over two hundred edge locations around the world. When someone in Tokyo visits your website, CloudFront serves it from the Tokyo edge location. When someone in London visits, they get it from London. This geographic distribution means your website loads quickly regardless of where your users are located. CloudFront also provides HTTPS security, caching controls, and DDoS protection through AWS Shield. The architecture works by creating a CloudFront distribution that points to your S3 bucket as the origin. Users access your website through the CloudFront URL, and CloudFront handles fetching content from S3 and caching it at edge locations for fast subsequent access.

Tomorrow I'll build both pieces of this architecture in sequence. First, I'll create the S3 bucket, upload website content, and get it working as a standalone static site. Then I'll add CloudFront on top to provide global distribution and performance optimization. By the end of tomorrow's three-hour build session, I'll have a live website accessible from anywhere in the world running on professional AWS infrastructure.

## Tomorrow's Execution Plan

I've blocked three hours on Saturday for this build. The first hour will focus on S3 - creating the bucket, preparing simple HTML content, uploading files, enabling static website hosting, and configuring permissions so the content is publicly readable. Permissions are typically where people encounter their first challenges because AWS's security model defaults to private access and requires explicit configuration to allow public reads.

The second hour will be CloudFront distribution creation and configuration. This includes selecting the S3 bucket as the origin, setting up caching behaviors, enabling HTTPS, and then waiting for the distribution to deploy globally, which takes fifteen to twenty minutes. I'll use that waiting time to review documentation and deepen my understanding of how CloudFront works.

The third hour is for testing, troubleshooting, and documentation. I'll access the website through both the S3 URL and the CloudFront URL to see the difference. I'll verify that the architecture works as expected. I'll take screenshots of the working site. And I'll document any problems I encountered and how I solved them. This documentation becomes my Day 6 GitHub entry on Sunday.

## Key Concepts Learned

Tonight reinforced the distinction between Python's three bracket types and when to use each one. Parentheses are for calling functions and executing code. Square brackets are for creating lists and accessing items by position. Curly braces are for dictionaries and sets where you need key-value relationships or unique collections. Understanding these syntactic differences helps me read code more fluently and choose the right data structure when writing my own code.

I also learned that function parameters and arguments work positionally - the order you pass values matters because Python maps them left to right to the parameter names in the function definition. This positional mapping means you need to pay attention to parameter order when calling functions, especially functions you didn't write yourself where you might not immediately remember what each position represents.

From the AWS planning discussion, I gained conceptual understanding of the relationship between storage and content delivery. S3 provides the storage layer where your actual files live. CloudFront provides the delivery layer that makes those files accessible quickly from anywhere in the world. This separation of concerns is a common pattern in cloud architecture - you have origin services that hold the canonical data and edge services that optimize delivery to end users.

## Readiness for Tomorrow

I feel prepared to execute tomorrow's build. My AWS account is set up with Free Tier credits. I understand what S3 and CloudFront do and why they work together. I have a realistic time allocation that accounts for learning, troubleshooting, and documentation. Most importantly, I have the right mindset - I'll attempt to solve problems independently using AWS documentation and research, but I'll ask for help if I get genuinely stuck. The goal isn't just to get a working website but to understand the architecture deeply enough to explain it to someone else.

I'm excited to show this first project to my mentor Andy. Having someone to share progress with adds accountability and makes the wins feel more meaningful. By Sunday evening, I'll have completed my Week 1 capstone project and will be ready to move into Week 2 with hands-on AWS experience under my belt.

---

**Days completed:** 5 of 90  
**Days remaining:** 85  
**Next milestone:** First AWS project (S3 + CloudFront static website)  
**Target completion:** January 7, 2026
